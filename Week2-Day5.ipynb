{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47133a5e-f3c5-4912-9121-9348e4f133ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Grouping of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c5ee96-7c21-4fe3-bbed-b2c620a1e3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SEVERITY DISTRIBUTION \n",
      "\n",
      "severity_level\n",
      "Low       489\n",
      "Medium     82\n",
      "High       29\n",
      "Name: count, dtype: int64\n",
      "\n",
      " SAMPLE PATIENT SEVERITY \n",
      "\n",
      "  patient_uid  severity_score severity_level\n",
      "0      P00000        0.571965           High\n",
      "1      P00001        0.532564           High\n",
      "2      P00002        0.983853           High\n",
      "3      P00003        0.460651           High\n",
      "4      P00004        0.504159           High\n",
      "5      P00005        0.000000            Low\n",
      "6      P00006        0.425007           High\n",
      "7      P00007        0.470549           High\n",
      "8      P00008        0.370591           High\n",
      "9      P00009        0.546997           High\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "# loading of pre-processed data\n",
    "df = pd.read_csv(r\"C:\\Users\\rajak\\Downloads\\AI Internship\\clinical_notes_preprocessed_no_spellcheck.csv\")\n",
    "df = df.iloc[:600].copy()\n",
    "assert \"note_preprocessed\" in df.columns\n",
    "# creating a unique patient ID\n",
    "df = df.reset_index(drop=True)\n",
    "df[\"patient_uid\"] = [\"P{:05d}\".format(i) for i in range(len(df))]\n",
    "# TF-IDF vectorisation\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=4000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2\n",
    ")\n",
    "tfidf_vectors = vectorizer.fit_transform(df[\"note_preprocessed\"])\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "# marked the severity indicators \n",
    "severity_indicators = [\n",
    "    \"icu\", \"intubation\", \"ventilator\", \"ards\",\n",
    "    \"respiratory failure\", \"oxygen\", \"desaturation\",\n",
    "    \"dyspnea\", \"shortness breath\", \"critical\"\n",
    "]\n",
    "severity_indices = [\n",
    "    i for i, term in enumerate(feature_names)\n",
    "    if any(key in term for key in severity_indicators)\n",
    "]\n",
    "# Compute severity score per patient\n",
    "severity_scores = tfidf_vectors[:, severity_indices].sum(axis=1).A1\n",
    "df[\"severity_score\"] = severity_scores\n",
    "# clustering severity into three groups\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "df[\"severity_cluster\"] = kmeans.fit_predict(\n",
    "    df[[\"severity_score\"]]\n",
    ")\n",
    "# mapping clusters into labels \n",
    "cluster_means = (\n",
    "    df.groupby(\"severity_cluster\")[\"severity_score\"]\n",
    "    .mean()\n",
    "    .sort_values()\n",
    ")\n",
    "severity_mapping = {\n",
    "    cluster_means.index[0]: \"Low\",\n",
    "    cluster_means.index[1]: \"Medium\",\n",
    "    cluster_means.index[2]: \"High\"\n",
    "}\n",
    "df[\"severity_level\"] = df[\"severity_cluster\"].map(severity_mapping)\n",
    "# final output\n",
    "print(\"\\n SEVERITY DISTRIBUTION \\n\")\n",
    "print(df[\"severity_level\"].value_counts())\n",
    "\n",
    "print(\"\\n SAMPLE PATIENT SEVERITY \\n\")\n",
    "print(df[[\"patient_uid\", \"severity_score\", \"severity_level\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf824ce4-2f79-4816-9578-dd407f76ee62",
   "metadata": {},
   "source": [
    "from this we have the severity level of the each subject based on the clinical terms. Then based on the severity level the patients have been grouped into high severity, medium severity and low severity. This helps to predict the severity level of the new from the existing case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79228308-6f9f-4eec-a92f-cd4f20adcea6",
   "metadata": {},
   "source": [
    "# loading the cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa813201-dad3-4a09-8028-b3b7f6292fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TOP 10 MOST SIMILAR PATIENT PAIRS \n",
      "\n",
      "       patient_1 patient_2  cosine_similarity\n",
      "258004       452       457           0.781737\n",
      "258000       452       453           0.709339\n",
      "44400         79        80           0.701907\n",
      "256805       450       456           0.688043\n",
      "258603       453       457           0.660064\n",
      "43801         78        80           0.653648\n",
      "43800         78        79           0.646245\n",
      "112201       198       200           0.631032\n",
      "32400         58        59           0.628265\n",
      "347400       612       613           0.622893\n",
      "\n",
      " TOP 10 MOST DISIMILAR PATIENT PAIRS \n",
      "\n",
      "       patient_1 patient_2  cosine_similarity\n",
      "139427       244       486           0.005071\n",
      "139457       244       520           0.006475\n",
      "139401       244       456           0.006761\n",
      "89100        156       475           0.006802\n",
      "294039       520       562           0.007074\n",
      "92547        162       317           0.007128\n",
      "222679       391       477           0.007155\n",
      "100481       178       475           0.007320\n",
      "44097         78       391           0.007549\n",
      "270638       477       520           0.007572\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# loading the cosine similarity matrix\n",
    "similarity_df = pd.read_csv(\n",
    "    r\"C:\\Users\\rajak\\Downloads\\AI Internship\\cosinesimilarity.csv\",\n",
    "    index_col=0\n",
    ")\n",
    "# Ensure indices are strings\n",
    "similarity_df.index = similarity_df.index.astype(str)\n",
    "similarity_df.columns = similarity_df.columns.astype(str)\n",
    "# removing the self-similarity\n",
    "np.fill_diagonal(similarity_df.values, np.nan)\n",
    "# converting to the dataframe\n",
    "pairs = (\n",
    "    similarity_df\n",
    "    .stack()\n",
    "    .reset_index()\n",
    ")\n",
    "pairs.columns = [\"patient_1\", \"patient_2\", \"cosine_similarity\"]\n",
    "# removing the duplicate pairs\n",
    "pairs[\"pair_key\"] = pairs.apply(\n",
    "    lambda x: \"_\".join(sorted([x[\"patient_1\"], x[\"patient_2\"]])),\n",
    "    axis=1\n",
    ")\n",
    "pairs = pairs.drop_duplicates(subset=\"pair_key\")\n",
    "pairs = pairs.drop(columns=\"pair_key\")\n",
    "# top 10 most similar pairs\n",
    "top_10_similar = pairs.sort_values(\n",
    "    by=\"cosine_similarity\",\n",
    "    ascending=False\n",
    ").head(10)\n",
    "# top 10 dissimilar pairs\n",
    "top_10_dissimilar = pairs.sort_values(\n",
    "    by=\"cosine_similarity\",\n",
    "    ascending=True\n",
    ").head(10)\n",
    "# displaying results\n",
    "print(\"\\n TOP 10 MOST SIMILAR PATIENT PAIRS \\n\")\n",
    "print(top_10_similar)\n",
    "print(\"\\n TOP 10 MOST DISIMILAR PATIENT PAIRS \\n\")\n",
    "print(top_10_dissimilar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66a04b0-e4e2-464b-894b-636cc7f34fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loaded the existing cosine similarity score file and found the top similar and disimilar pairs. B"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47133a5e-f3c5-4912-9121-9348e4f133ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Grouping of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c5ee96-7c21-4fe3-bbed-b2c620a1e3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SEVERITY DISTRIBUTION \n",
      "\n",
      "severity_level\n",
      "Low       489\n",
      "Medium     82\n",
      "High       29\n",
      "Name: count, dtype: int64\n",
      "\n",
      " SAMPLE PATIENT SEVERITY \n",
      "\n",
      "  patient_uid  severity_score severity_level\n",
      "0      P00000        0.571965           High\n",
      "1      P00001        0.532564           High\n",
      "2      P00002        0.983853           High\n",
      "3      P00003        0.460651           High\n",
      "4      P00004        0.504159           High\n",
      "5      P00005        0.000000            Low\n",
      "6      P00006        0.425007           High\n",
      "7      P00007        0.470549           High\n",
      "8      P00008        0.370591           High\n",
      "9      P00009        0.546997           High\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "# loading of pre-processed data\n",
    "df = pd.read_csv(r\"C:\\Users\\rajak\\Downloads\\AI Internship\\clinical_notes_preprocessed_no_spellcheck.csv\")\n",
    "df = df.iloc[:600].copy()\n",
    "assert \"note_preprocessed\" in df.columns\n",
    "# creating a unique patient ID\n",
    "df = df.reset_index(drop=True)\n",
    "df[\"patient_uid\"] = [\"P{:05d}\".format(i) for i in range(len(df))]\n",
    "# TF-IDF vectorisation\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=4000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2\n",
    ")\n",
    "tfidf_vectors = vectorizer.fit_transform(df[\"note_preprocessed\"])\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "# marked the severity indicators \n",
    "severity_indicators = [\n",
    "    \"icu\", \"intubation\", \"ventilator\", \"ards\",\n",
    "    \"respiratory failure\", \"oxygen\", \"desaturation\",\n",
    "    \"dyspnea\", \"shortness breath\", \"critical\"\n",
    "]\n",
    "severity_indices = [\n",
    "    i for i, term in enumerate(feature_names)\n",
    "    if any(key in term for key in severity_indicators)\n",
    "]\n",
    "# Compute severity score per patient\n",
    "severity_scores = tfidf_vectors[:, severity_indices].sum(axis=1).A1\n",
    "df[\"severity_score\"] = severity_scores\n",
    "# clustering severity into three groups\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "df[\"severity_cluster\"] = kmeans.fit_predict(\n",
    "    df[[\"severity_score\"]]\n",
    ")\n",
    "# mapping clusters into labels \n",
    "cluster_means = (\n",
    "    df.groupby(\"severity_cluster\")[\"severity_score\"]\n",
    "    .mean()\n",
    "    .sort_values()\n",
    ")\n",
    "severity_mapping = {\n",
    "    cluster_means.index[0]: \"Low\",\n",
    "    cluster_means.index[1]: \"Medium\",\n",
    "    cluster_means.index[2]: \"High\"\n",
    "}\n",
    "df[\"severity_level\"] = df[\"severity_cluster\"].map(severity_mapping)\n",
    "# final output\n",
    "print(\"\\n SEVERITY DISTRIBUTION \\n\")\n",
    "print(df[\"severity_level\"].value_counts())\n",
    "\n",
    "print(\"\\n SAMPLE PATIENT SEVERITY \\n\")\n",
    "print(df[[\"patient_uid\", \"severity_score\", \"severity_level\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf824ce4-2f79-4816-9578-dd407f76ee62",
   "metadata": {},
   "source": [
    "from this we have the severity level of the each subject based on the clinical terms. Then based on the severity level the patients have been grouped into high severity, medium severity and low severity. This helps to predict the severity level of the new from the existing case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79228308-6f9f-4eec-a92f-cd4f20adcea6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# loading the cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa813201-dad3-4a09-8028-b3b7f6292fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TOP 10 MOST SIMILAR PATIENT PAIRS \n",
      "\n",
      "       patient_1 patient_2  cosine_similarity\n",
      "258004       452       457           0.781737\n",
      "258000       452       453           0.709339\n",
      "44400         79        80           0.701907\n",
      "256805       450       456           0.688043\n",
      "258603       453       457           0.660064\n",
      "43801         78        80           0.653648\n",
      "43800         78        79           0.646245\n",
      "112201       198       200           0.631032\n",
      "32400         58        59           0.628265\n",
      "347400       612       613           0.622893\n",
      "\n",
      " TOP 10 MOST DISIMILAR PATIENT PAIRS \n",
      "\n",
      "       patient_1 patient_2  cosine_similarity\n",
      "139427       244       486           0.005071\n",
      "139457       244       520           0.006475\n",
      "139401       244       456           0.006761\n",
      "89100        156       475           0.006802\n",
      "294039       520       562           0.007074\n",
      "92547        162       317           0.007128\n",
      "222679       391       477           0.007155\n",
      "100481       178       475           0.007320\n",
      "44097         78       391           0.007549\n",
      "270638       477       520           0.007572\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# loading the cosine similarity matrix\n",
    "similarity_df = pd.read_csv(\n",
    "    r\"C:\\Users\\rajak\\Downloads\\AI Internship\\cosinesimilarity.csv\",\n",
    "    index_col=0\n",
    ")\n",
    "# Ensure indices are strings\n",
    "similarity_df.index = similarity_df.index.astype(str)\n",
    "similarity_df.columns = similarity_df.columns.astype(str)\n",
    "# removing the self-similarity\n",
    "np.fill_diagonal(similarity_df.values, np.nan)\n",
    "# converting to the dataframe\n",
    "pairs = (\n",
    "    similarity_df\n",
    "    .stack()\n",
    "    .reset_index()\n",
    ")\n",
    "pairs.columns = [\"patient_1\", \"patient_2\", \"cosine_similarity\"]\n",
    "# removing the duplicate pairs\n",
    "pairs[\"pair_key\"] = pairs.apply(\n",
    "    lambda x: \"_\".join(sorted([x[\"patient_1\"], x[\"patient_2\"]])),\n",
    "    axis=1\n",
    ")\n",
    "pairs = pairs.drop_duplicates(subset=\"pair_key\")\n",
    "pairs = pairs.drop(columns=\"pair_key\")\n",
    "# top 10 most similar pairs\n",
    "top_10_similar = pairs.sort_values(\n",
    "    by=\"cosine_similarity\",\n",
    "    ascending=False\n",
    ").head(10)\n",
    "# top 10 dissimilar pairs\n",
    "top_10_dissimilar = pairs.sort_values(\n",
    "    by=\"cosine_similarity\",\n",
    "    ascending=True\n",
    ").head(10)\n",
    "# displaying results\n",
    "print(\"\\n TOP 10 MOST SIMILAR PATIENT PAIRS \\n\")\n",
    "print(top_10_similar)\n",
    "print(\"\\n TOP 10 MOST DISIMILAR PATIENT PAIRS \\n\")\n",
    "print(top_10_dissimilar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66a04b0-e4e2-464b-894b-636cc7f34fe8",
   "metadata": {},
   "source": [
    "Loaded the existing cosine similarity score file and found the top similar and disimilar pairs. Based on this similarity value we can be able to easily find the most similar existing patient to the ne patient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d5642c-c8f7-4c58-8383-557024067626",
   "metadata": {},
   "source": [
    "# New patient 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d329336-29cb-4d56-a27f-9896f2385de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter new patient clinical terms:\n",
      " A 60 year-old male presented with fever, persistent dry cough, and shortness of breath. The patient experienced oxygen desaturation on exertion and was diagnosed with viral pneumonia.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ORIGINAL INPUT \n",
      "\n",
      "A 60 year-old male presented with fever, persistent dry cough, and shortness of breath. The patient experienced oxygen desaturation on exertion and was diagnosed with viral pneumonia.\n",
      "\n",
      "  MOST SIMILAR EXISTING PATIENT \n",
      "Patient ID: P00000\n",
      "Cosine Similarity Score: 0.2423\n",
      "\n",
      " SHARED CLINICAL TERMS (TF-IDF FILTERED) \n",
      "desaturation, oxygen desaturation\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# loading of pre-processed data\n",
    "df = pd.read_csv(r\"C:\\Users\\rajak\\Downloads\\AI Internship\\clinical_notes_preprocessed_no_spellcheck.csv\")\n",
    "df = df.iloc[:600].copy()\n",
    "assert \"note_preprocessed\" in df.columns, \"Missing 'note_preprocessed' column\"\n",
    "# Create unique patient ID\n",
    "df = df.reset_index(drop=True)\n",
    "df[\"patient_uid\"] = [\"P{:05d}\".format(i) for i in range(len(df))]\n",
    "# vectorisation of the existing data\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2\n",
    ")\n",
    "tfidf_existing = vectorizer.fit_transform(df[\"note_preprocessed\"])\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "# getting the user input to process\n",
    "new_case_text = input(\"\\nEnter new patient clinical terms:\\n\")\n",
    "# displaying the original input\n",
    "print(\"\\n  ORIGINAL INPUT \\n\")\n",
    "print(new_case_text)\n",
    "# Match dataset assumptions\n",
    "new_case_text = new_case_text.lower()\n",
    "# Vectorize input using SAME TF-IDF space\n",
    "tfidf_input = vectorizer.transform([new_case_text])\n",
    "# finding the most similar existing patient\n",
    "similarity_scores = cosine_similarity(tfidf_input, tfidf_existing)[0]\n",
    "most_similar_index = similarity_scores.argmax()\n",
    "most_similar_score = similarity_scores[most_similar_index]\n",
    "most_similar_patient_id = df.loc[most_similar_index, \"patient_uid\"]\n",
    "most_similar_note = df.loc[most_similar_index, \"note_preprocessed\"]\n",
    "# extracting the clinical shared medical terms\n",
    "def get_top_tfidf_terms(tfidf_vector, top_n=15):\n",
    "    dense_vec = tfidf_vector.toarray().flatten()\n",
    "    top_indices = dense_vec.argsort()[-top_n:][::-1]\n",
    "    return set(feature_names[top_indices])\n",
    "# Top TF-IDF terms from input and similar patient\n",
    "input_top_terms = get_top_tfidf_terms(tfidf_input, top_n=15)\n",
    "patient_top_terms = get_top_tfidf_terms(\n",
    "    tfidf_existing[most_similar_index], top_n=15\n",
    ")\n",
    "# getting medically meaningful terms\n",
    "shared_clinical_terms = sorted(\n",
    "    input_top_terms.intersection(patient_top_terms)\n",
    ")\n",
    "# displaying the result\n",
    "print(\"\\n  MOST SIMILAR EXISTING PATIENT \")\n",
    "print(\"Patient ID:\", most_similar_patient_id)\n",
    "print(\"Cosine Similarity Score:\", round(most_similar_score, 4))\n",
    "\n",
    "print(\"\\n SHARED CLINICAL TERMS (TF-IDF FILTERED) \")\n",
    "print(\", \".join(shared_clinical_terms))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08f1567-0a89-4f2d-9de6-d37f42aa4919",
   "metadata": {},
   "source": [
    "finding the most similar existing patient for the new given input. from this we also find the most important shared common symptoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27db4dab-c433-44c6-a140-3f73b1d05742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter new patient clinical description:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " A 60 year-old male presented with fever, persistent dry cough, and shortness of breath. The patient experienced oxygen desaturation on exertion and was diagnosed with viral pneumonia.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TOP 5 MOST SIMILAR PATIENTS \n",
      "\n",
      "patient_uid  cosine_similarity\n",
      "     P00000           0.208419\n",
      "     P00005           0.189355\n",
      "     P00131           0.163337\n",
      "     P00191           0.142388\n",
      "     P00002           0.142220\n",
      "\n",
      " INFERRED SEVERITY FOR NEW PATIENT \n",
      "Predicted Severity Level: High\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "# loading of pre-processed data\n",
    "df = pd.read_csv(\n",
    "    r\"C:\\Users\\rajak\\Downloads\\AI Internship\\clinical_notes_preprocessed_no_spellcheck.csv\"\n",
    ")\n",
    "df = df.iloc[:600].copy()\n",
    "assert \"note_preprocessed\" in df.columns, \"note_preprocessed column missing\"\n",
    "# creating a unique patient ID\n",
    "df = df.reset_index(drop=True)\n",
    "df[\"patient_uid\"] = [\"P{:05d}\".format(i) for i in range(len(df))]\n",
    "# Tf IDF vectorisation\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=4000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2\n",
    ")\n",
    "tfidf_vectors = vectorizer.fit_transform(df[\"note_preprocessed\"])\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "# severity scoring \n",
    "severity_indicators = [\n",
    "    \"icu\", \"intubation\", \"ventilator\", \"ards\",\n",
    "    \"respiratory failure\", \"oxygen\", \"desaturation\",\n",
    "    \"dyspnea\", \"shortness breath\", \"critical\"\n",
    "]\n",
    "\n",
    "severity_indices = [\n",
    "    i for i, term in enumerate(feature_names)\n",
    "    if any(key in term for key in severity_indicators)\n",
    "]\n",
    "\n",
    "severity_scores = tfidf_vectors[:, severity_indices].sum(axis=1).A1\n",
    "df[\"severity_score\"] = severity_scores\n",
    "# clustering the subjects based on the severity level\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "df[\"severity_cluster\"] = kmeans.fit_predict(df[[\"severity_score\"]])\n",
    "\n",
    "cluster_means = (\n",
    "    df.groupby(\"severity_cluster\")[\"severity_score\"]\n",
    "    .mean()\n",
    "    .sort_values()\n",
    ")\n",
    "\n",
    "severity_mapping = {\n",
    "    cluster_means.index[0]: \"Low\",\n",
    "    cluster_means.index[1]: \"Medium\",\n",
    "    cluster_means.index[2]: \"High\"\n",
    "}\n",
    "\n",
    "df[\"severity_level\"] = df[\"severity_cluster\"].map(severity_mapping)\n",
    "# providing user input\n",
    "print(\"\\nEnter new patient clinical description:\")\n",
    "new_patient_text = input().lower()\n",
    "\n",
    "tfidf_input = vectorizer.transform([new_patient_text])\n",
    "# finding top 5 existing similar patient\n",
    "similarity_scores = cosine_similarity(tfidf_input, tfidf_vectors)[0]\n",
    "top_5_indices = similarity_scores.argsort()[-5:][::-1]\n",
    "top_5_similar = df.iloc[top_5_indices].copy()\n",
    "top_5_similar[\"cosine_similarity\"] = similarity_scores[top_5_indices]\n",
    "# zinfering the severity level for the new patient\n",
    "severity_weighted = {}\n",
    "\n",
    "for _, row in top_5_similar.iterrows():\n",
    "    severity_weighted[row[\"severity_level\"]] = (\n",
    "        severity_weighted.get(row[\"severity_level\"], 0)\n",
    "        + row[\"cosine_similarity\"]\n",
    "    )\n",
    "\n",
    "predicted_severity = max(severity_weighted, key=severity_weighted.get)\n",
    "# displaying result\n",
    "print(\"\\n TOP 5 MOST SIMILAR PATIENTS \\n\")\n",
    "print(\n",
    "    top_5_similar[\n",
    "        [\"patient_uid\", \"cosine_similarity\"]\n",
    "    ].to_string(index=False)\n",
    ")\n",
    "\n",
    "print(\"\\n INFERRED SEVERITY FOR NEW PATIENT \")\n",
    "print(\"Predicted Severity Level:\", predicted_severity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f11c4-ea97-4f05-95ef-c7ba77a128cd",
   "metadata": {},
   "source": [
    "from these code we have found the top 5 similar existing patient and the severity level of the new patient. This severity level would be the indicator for the clinicians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd27fa3b-b35e-4f97-b302-d13990c6ba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter new patient clinical terms:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " A 60 year-old male presented with fever, persistent dry cough, and shortness of breath. The patient experienced oxygen desaturation on exertion and was diagnosed with viral pneumonia.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MOST SIMILAR PATIENTS \n",
      "    patient_uid\n",
      "0        P00000\n",
      "5        P00005\n",
      "131      P00131\n",
      "191      P00191\n",
      "2        P00002\n",
      "\n",
      " SHARED CLINICAL SYMPTOMS \n",
      "- cough\n",
      "- fever\n",
      "- dry cough\n",
      "\n",
      " TREATMENT ADOPTED IN SIMILAR CASES\n",
      "- rehabilitation\n",
      "- physical therapy\n",
      "- breathing exercise\n",
      "\n",
      " ESTIMATED RECOVERY PERIOD\n",
      "Not explicitly stated\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# loading of the pre-processed data\n",
    "df = pd.read_csv(\n",
    "    r\"C:\\Users\\rajak\\Downloads\\AI Internship\\clinical_notes_preprocessed_no_spellcheck.csv\"\n",
    ")\n",
    "df = df.iloc[:600].copy()\n",
    "assert \"note_preprocessed\" in df.columns\n",
    "df = df.reset_index(drop=True)\n",
    "df[\"patient_uid\"] = [f\"P{i:05d}\" for i in range(len(df))]\n",
    "# vectorisation\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=4000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2\n",
    ")\n",
    "tfidf_vectors = vectorizer.fit_transform(df[\"note_preprocessed\"])\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "# key words indicating severity\n",
    "severity_terms = [\n",
    "    \"icu\", \"intubation\", \"ventilator\", \"ards\",\n",
    "    \"respiratory failure\", \"oxygen\", \"desaturation\",\n",
    "    \"dyspnea\", \"shortness breath\", \"critical\"\n",
    "]\n",
    "\n",
    "severity_idx = [\n",
    "    i for i, term in enumerate(feature_names)\n",
    "    if any(k in term for k in severity_terms)\n",
    "]\n",
    "\n",
    "df[\"severity_score\"] = tfidf_vectors[:, severity_idx].sum(axis=1).A1\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "df[\"severity_cluster\"] = kmeans.fit_predict(df[[\"severity_score\"]])\n",
    "\n",
    "cluster_means = (\n",
    "    df.groupby(\"severity_cluster\")[\"severity_score\"]\n",
    "    .mean()\n",
    "    .sort_values()\n",
    ")\n",
    "\n",
    "severity_map = {\n",
    "    cluster_means.index[0]: \"Low\",\n",
    "    cluster_means.index[1]: \"Medium\",\n",
    "    cluster_means.index[2]: \"High\"\n",
    "}\n",
    "df[\"severity_level\"] = df[\"severity_cluster\"].map(severity_map)\n",
    "# user input \n",
    "print(\"\\nEnter new patient clinical terms:\")\n",
    "new_text = input().lower()\n",
    "tfidf_input = vectorizer.transform([new_text])\n",
    "# Top 5 similar patient\n",
    "sim_scores = cosine_similarity(tfidf_input, tfidf_vectors)[0]\n",
    "top_5_idx = sim_scores.argsort()[-5:][::-1]\n",
    "top_5 = df.iloc[top_5_idx].copy()\n",
    "# symptom extraction\n",
    "SYMPTOM_TERMS = [\n",
    "    \"fever\", \"cough\", \"dry cough\", \"dyspnea\",\n",
    "    \"shortness breath\", \"hypoxia\", \"fatigue\",\n",
    "    \"chest pain\", \"oxygen desaturation\",\n",
    "    \"tachypnea\", \"respiratory distress\"\n",
    "]\n",
    "\n",
    "def extract_symptoms(text):\n",
    "    found = []\n",
    "    for term in SYMPTOM_TERMS:\n",
    "        if term in text:\n",
    "            found.append(term)\n",
    "    return found\n",
    "\n",
    "symptoms = []\n",
    "for idx in top_5_idx:\n",
    "    symptoms.extend(extract_symptoms(df.loc[idx, \"note_preprocessed\"]))\n",
    "\n",
    "top_symptoms = [s for s, _ in Counter(symptoms).most_common(3)]\n",
    "# treatment extraction\n",
    "TREATMENT_TERMS = [\n",
    "    \"oxygen therapy\", \"mechanical ventilation\", \"ventilation\",\n",
    "    \"intubation\", \"ecmo\",\n",
    "    \"physiotherapy\", \"physical therapy\",\n",
    "    \"breathing exercise\", \"rehabilitation\",\n",
    "    \"corticosteroid\", \"steroid\",\n",
    "    \"antibiotic\", \"antiviral\",\n",
    "    \"dialysis\", \"supportive care\"\n",
    "]\n",
    "\n",
    "def extract_treatments(text):\n",
    "    return [t for t in TREATMENT_TERMS if t in text]\n",
    "\n",
    "treatments = []\n",
    "for idx in top_5_idx:\n",
    "    treatments.extend(extract_treatments(df.loc[idx, \"note_preprocessed\"]))\n",
    "\n",
    "top_treatments = [t for t, _ in Counter(treatments).most_common(3)]\n",
    "# recovery time \n",
    "def extract_days(text):\n",
    "    return [int(x) for x in re.findall(r'day\\s*(\\d+)', text)]\n",
    "\n",
    "days = []\n",
    "for idx in top_5_idx:\n",
    "    days.extend(extract_days(df.loc[idx, \"note_preprocessed\"]))\n",
    "\n",
    "estimated_recovery = (\n",
    "    f\"{int(np.median(days))} days\"\n",
    "    if days else \"Not explicitly stated\"\n",
    ")\n",
    "# final output\n",
    "print(\"\\n MOST SIMILAR PATIENTS \")\n",
    "print(top_5[[\"patient_uid\" ]])\n",
    "\n",
    "print(\"\\n SHARED CLINICAL SYMPTOMS \")\n",
    "for s in top_symptoms:\n",
    "    print(\"-\", s)\n",
    "\n",
    "print(\"\\n TREATMENT ADOPTED IN SIMILAR CASES\")\n",
    "for t in top_treatments:\n",
    "    print(\"-\", t)\n",
    "\n",
    "print(\"\\n ESTIMATED RECOVERY PERIOD\")\n",
    "print(estimated_recovery)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b380981-6b9d-4809-8655-2df01cb2d362",
   "metadata": {},
   "source": [
    "From the above given code we have found the the treatment that need to be provided to the new patient based on the existing patient records. Then also found the recovery period and shared symptoms among the existing patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a00d5d8-59b6-4a97-b343-bb992008cd28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
